{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook for CIFAR image classification training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weibinchen/miniforge3/envs/torch-gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from utils import class_accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_utils import read_data_sets\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from optim.FishLeg import FishLeg, FISH_LIKELIHOODS, initialise_FishModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, test_loader, opt, likelihood, class_accuracy, epochs=2, device='cuda'):\n",
    "    st = time.time()\n",
    "    eval_time = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "            for n, (batch_data, batch_labels) in enumerate(tepoch, start=1):\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "                batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                output = model(batch_data)\n",
    "\n",
    "                loss = likelihood(output, batch_labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_acc += class_accuracy(output, batch_labels).item()\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                et = time.time()\n",
    "                if n % 50 == 0:\n",
    "                    model.eval()\n",
    "\n",
    "                    running_test_loss = 0\n",
    "                    running_test_acc = 0\n",
    "\n",
    "                    for m, (test_batch_data, test_batch_labels) in enumerate(test_loader, start=1):\n",
    "                        test_batch_data, test_batch_labels = test_batch_data.to(device), test_batch_labels.to(device)\n",
    "\n",
    "                        test_output = model(test_batch_data)\n",
    "\n",
    "                        test_loss = likelihood(test_output, test_batch_labels)\n",
    "\n",
    "                        running_test_loss += test_loss.item()\n",
    "                        running_test_acc += class_accuracy(test_output, test_batch_labels).item()\n",
    "\n",
    "                    running_test_loss /= m\n",
    "                    running_test_acc /= m\n",
    "\n",
    "                    tepoch.set_postfix(acc=100 * running_acc / n, test_acc=running_test_acc * 100)\n",
    "                    model.train()\n",
    "                    eval_time += time.time() - et\n",
    "\n",
    "            epoch_time = time.time() - st - eval_time\n",
    "            tepoch.set_postfix(loss=running_loss / n, test_loss=running_test_loss, epoch_time=epoch_time)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading data for MNIST\n",
      "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Data read from ../data/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Data read from ../data/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Succesfully loaded MNIST dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = read_data_sets(\"MNIST\", \"../data/\", if_autoencoder=False, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  60000\n",
      "Test size:  10000\n",
      "Image shape:  (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "## Dataset\n",
    "train_dataset = dataset.train\n",
    "test_dataset = dataset.test\n",
    "\n",
    "print(\"Train size: \", train_dataset.num_examples)\n",
    "print(\"Test size: \", test_dataset.num_examples)\n",
    "print(\"Image shape: \", train_dataset.images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "aux_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, shuffle=True, batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=16,\n",
    "        kernel_size=5,\n",
    "        stride=1,\n",
    "        padding=2,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # nn.Conv2d(\n",
    "    #     in_channels=16,\n",
    "    #     out_channels=32,\n",
    "    #     kernel_size=5,\n",
    "    #     stride=1,\n",
    "    #     padding=2,\n",
    "    # ),\n",
    "    # nn.ReLU(),\n",
    "    # nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 14 * 14, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?batch/s]/Users/weibinchen/Desktop/UCL/PhD_Year_1/FishLeg/examples/data_utils.py:137: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self._images[idx]), torch.tensor(self._labels[idx])\n",
      "Epoch 1: 100%|██████████| 120/120 [00:08<00:00, 14.60batch/s, acc=80.3, test_acc=90.3]\n",
      "Epoch 2: 100%|██████████| 120/120 [00:08<00:00, 14.97batch/s, acc=91.7, test_acc=93.3]\n"
     ]
    }
   ],
   "source": [
    "likelihood = FISH_LIKELIHOODS[\"softmax\"](device=device)\n",
    "\n",
    "lr = 0.0005\n",
    "# betas = (0.7, 0.9)\n",
    "weight_decay = 1e-5\n",
    "# eps = 1e-8\n",
    "\n",
    "opt = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    # betas=betas,\n",
    "    weight_decay=weight_decay,\n",
    "    # eps=eps,\n",
    ")\n",
    "\n",
    "\n",
    "trained_model = train_model(model, train_loader, test_loader, opt, likelihood, class_accuracy, epochs=2, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FishLeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 120/120 [00:16<00:00,  7.44batch/s, acc=94, test_acc=95.2] \n",
      "Epoch 2: 100%|██████████| 120/120 [00:15<00:00,  7.51batch/s, acc=95.5, test_acc=96.1]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.02\n",
    "beta = 0.9\n",
    "weight_decay = 1e-5\n",
    "\n",
    "aux_lr = 1e-4\n",
    "aux_eps = 1e-8\n",
    "scale_factor = 1\n",
    "damping = 0.1\n",
    "update_aux_every = 3\n",
    "\n",
    "initialization = \"normal\"\n",
    "normalization = True\n",
    "\n",
    "model = initialise_FishModel(\n",
    "    model, module_names=\"__ALL__\", fish_scale=scale_factor / damping\n",
    ")\n",
    "\n",
    "opt = FishLeg(\n",
    "    model,\n",
    "    aux_loader,\n",
    "    likelihood,\n",
    "    lr=lr,\n",
    "    beta=beta,\n",
    "    weight_decay=weight_decay,\n",
    "    aux_lr=aux_lr,\n",
    "    aux_betas=(0.9, 0.999),\n",
    "    aux_eps=aux_eps,\n",
    "    damping=damping,\n",
    "    update_aux_every=update_aux_every,\n",
    "    # writer=writer,\n",
    "    method=\"antithetic\",\n",
    "    method_kwargs={\"eps\": 1e-4},\n",
    "    precondition_aux=True,\n",
    ")\n",
    "trained_model = train_model(model, train_loader, test_loader, opt, likelihood, class_accuracy, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 120/120 [00:09<00:00, 12.80batch/s, acc=97.5, test_acc=97.6]\n",
      "Epoch 2:  13%|█▎        | 16/120 [00:01<00:06, 15.23batch/s]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "dee4cb6648085172192ebedd48c9a6f014ffcad5925711ae86db60fc7a3e5218"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
