{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example notebook for CIFAR image classification training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from utils import class_accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data_utils import read_data_sets\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from optim.FishLeg import FishLeg, FISH_LIKELIHOODS, initialise_FishModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin loading data for MNIST\n",
      "Data read from ../data/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Data read from ../data/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Succesfully loaded MNIST dataset.\n"
     ]
    }
   ],
   "source": [
    "dataset = read_data_sets(\"MNIST\", \"../data/\", if_autoencoder=False, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  60000\n",
      "Test size:  10000\n",
      "Image shape:  (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "## Dataset\n",
    "train_dataset = dataset.train\n",
    "test_dataset = dataset.test\n",
    "\n",
    "print(\"Train size: \", train_dataset.num_examples)\n",
    "print(\"Test size: \", test_dataset.num_examples)\n",
    "print(\"Image shape: \", train_dataset.images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_dataset.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "aux_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, shuffle=True, batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=16,\n",
    "        kernel_size=5,\n",
    "        stride=1,\n",
    "        padding=2,\n",
    "    ),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # nn.Conv2d(\n",
    "    #     in_channels=16,\n",
    "    #     out_channels=32,\n",
    "    #     kernel_size=5,\n",
    "    #     stride=1,\n",
    "    #     padding=2,\n",
    "    # ),\n",
    "    # nn.ReLU(),\n",
    "    # nn.MaxPool2d(kernel_size=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 14 * 14, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = FISH_LIKELIHOODS[\"softmax\"](device=device)\n",
    "\n",
    "lr = 0.0005\n",
    "# betas = (0.7, 0.9)\n",
    "weight_decay = 1e-5\n",
    "# eps = 1e-8\n",
    "\n",
    "opt = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    # betas=betas,\n",
    "    weight_decay=weight_decay,\n",
    "    # eps=eps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 120/120 [00:03<00:00, 33.05batch/s, acc=97, test_acc=97.2]\n",
      "Epoch 2: 100%|██████████| 120/120 [00:03<00:00, 32.02batch/s, acc=97.3, test_acc=97.5]\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "st = time.time()\n",
    "eval_time = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        for n, (batch_data, batch_labels) in enumerate(tepoch, start=1):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            batch_data, batch_labels = (\n",
    "                batch_data.to(device),\n",
    "                batch_labels.to(device),\n",
    "            )\n",
    "\n",
    "            opt.zero_grad()\n",
    "            output = model(batch_data)\n",
    "\n",
    "            loss = likelihood(output, batch_labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            running_acc += class_accuracy(output, batch_labels).item()\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            et = time.time()\n",
    "            if n % 50 == 0:\n",
    "                model.eval()\n",
    "\n",
    "                running_test_loss = 0\n",
    "                running_test_acc = 0\n",
    "\n",
    "                for m, (test_batch_data, test_batch_labels) in enumerate(\n",
    "                    test_loader, start=1\n",
    "                ):\n",
    "                    test_batch_data, test_batch_labels = test_batch_data.to(\n",
    "                        device\n",
    "                    ), test_batch_labels.to(device)\n",
    "\n",
    "                    test_output = model(test_batch_data)\n",
    "\n",
    "                    test_loss = likelihood(test_output, test_batch_labels)\n",
    "\n",
    "                    running_test_loss += test_loss.item()\n",
    "\n",
    "                    running_test_acc += class_accuracy(\n",
    "                        test_output, test_batch_labels\n",
    "                    ).item()\n",
    "\n",
    "                running_test_loss /= m\n",
    "                running_test_acc /= m\n",
    "\n",
    "                tepoch.set_postfix(\n",
    "                    acc=100 * running_acc / n, test_acc=running_test_acc * 100\n",
    "                )\n",
    "                model.train()\n",
    "                eval_time += time.time() - et\n",
    "\n",
    "        epoch_time = time.time() - st - eval_time\n",
    "\n",
    "        tepoch.set_postfix(\n",
    "            loss=running_loss / n, test_loss=running_test_loss, epoch_time=epoch_time\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FishLeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.02\n",
    "beta = 0.9\n",
    "weight_decay = 1e-5\n",
    "\n",
    "aux_lr = 1e-4\n",
    "aux_eps = 1e-8\n",
    "scale_factor = 1\n",
    "damping = 0.1\n",
    "update_aux_every = 3\n",
    "\n",
    "initialization = \"normal\"\n",
    "normalization = True\n",
    "\n",
    "model = initialise_FishModel(\n",
    "    model, module_names=\"__ALL__\", fish_scale=scale_factor / damping\n",
    ")\n",
    "\n",
    "opt = FishLeg(\n",
    "    model,\n",
    "    aux_loader,\n",
    "    likelihood,\n",
    "    lr=lr,\n",
    "    beta=beta,\n",
    "    weight_decay=weight_decay,\n",
    "    aux_lr=aux_lr,\n",
    "    aux_betas=(0.9, 0.999),\n",
    "    aux_eps=aux_eps,\n",
    "    damping=damping,\n",
    "    update_aux_every=update_aux_every,\n",
    "    # writer=writer,\n",
    "    method=\"antithetic\",\n",
    "    method_kwargs={\"eps\": 1e-4},\n",
    "    precondition_aux=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 120/120 [00:09<00:00, 12.80batch/s, acc=97.5, test_acc=97.6]\n",
      "Epoch 2:  13%|█▎        | 16/120 [00:01<00:06, 15.23batch/s]"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "st = time.time()\n",
    "eval_time = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        for n, (batch_data, batch_labels) in enumerate(tepoch, start=1):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            batch_data, batch_labels = (\n",
    "                batch_data.to(device),\n",
    "                batch_labels.to(device),\n",
    "            )\n",
    "\n",
    "            opt.zero_grad()\n",
    "            output = model(batch_data)\n",
    "\n",
    "            loss = likelihood(output, batch_labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            running_acc += class_accuracy(output, batch_labels).item()\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            et = time.time()\n",
    "            if n % 50 == 0:\n",
    "                model.eval()\n",
    "\n",
    "                running_test_loss = 0\n",
    "                running_test_acc = 0\n",
    "\n",
    "                for m, (test_batch_data, test_batch_labels) in enumerate(\n",
    "                    test_loader, start=1\n",
    "                ):\n",
    "                    test_batch_data, test_batch_labels = test_batch_data.to(\n",
    "                        device\n",
    "                    ), test_batch_labels.to(device)\n",
    "\n",
    "                    test_output = model(test_batch_data)\n",
    "\n",
    "                    test_loss = likelihood(test_output, test_batch_labels)\n",
    "\n",
    "                    running_test_loss += test_loss.item()\n",
    "\n",
    "                    running_test_acc += class_accuracy(\n",
    "                        test_output, test_batch_labels\n",
    "                    ).item()\n",
    "\n",
    "                running_test_loss /= m\n",
    "                running_test_acc /= m\n",
    "\n",
    "                tepoch.set_postfix(\n",
    "                    acc=100 * running_acc / n, test_acc=running_test_acc * 100\n",
    "                )\n",
    "                model.train()\n",
    "                eval_time += time.time() - et\n",
    "\n",
    "        epoch_time = time.time() - st - eval_time\n",
    "\n",
    "        tepoch.set_postfix(\n",
    "            loss=running_loss / n, test_loss=running_test_loss, epoch_time=epoch_time\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fishlegnotebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
